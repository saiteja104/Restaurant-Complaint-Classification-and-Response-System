{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "      <th>Cleaned_Name</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Category</th>\n",
       "      <th>Is_Repeated</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "      <th>Review_Days</th>\n",
       "      <th>Response_Days</th>\n",
       "      <th>...</th>\n",
       "      <th>Food Options</th>\n",
       "      <th>Food Quality</th>\n",
       "      <th>Atmosphere</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Hygiene</th>\n",
       "      <th>Others</th>\n",
       "      <th>Severity_Label</th>\n",
       "      <th>Urgency_Label</th>\n",
       "      <th>Frequency_Label</th>\n",
       "      <th>Unique_Customer_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>stop eating place visited bangalores nd punes ...</td>\n",
       "      <td>pramod kumar</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>['Others']</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>No Response</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>food service ambience</td>\n",
       "      <td>abhinav deep</td>\n",
       "      <td>9.0</td>\n",
       "      <td>['Food Quality', 'Atmosphere', 'Service Issue']</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>High Satisfaction</td>\n",
       "      <td>365.0</td>\n",
       "      <td>365</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>idiotic varieties price charged varieties boil...</td>\n",
       "      <td>vijay nammi</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>['Others']</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.388889</td>\n",
       "      <td>No Response</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>posting live one worst places dont visit pathe...</td>\n",
       "      <td>surya ajay</td>\n",
       "      <td>34.0</td>\n",
       "      <td>['Service Issue', 'Food Quality']</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.772727</td>\n",
       "      <td>High Satisfaction</td>\n",
       "      <td>365.0</td>\n",
       "      <td>365</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pure vegetarians ordered veg biryani swiggy go...</td>\n",
       "      <td>sai hithesh</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['Food Options']</td>\n",
       "      <td>False</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>No Response</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     Cleaned_Review  \\\n",
       "0           0  stop eating place visited bangalores nd punes ...   \n",
       "1           1                              food service ambience   \n",
       "2           2  idiotic varieties price charged varieties boil...   \n",
       "3           3  posting live one worst places dont visit pathe...   \n",
       "4           4  pure vegetarians ordered veg biryani swiggy go...   \n",
       "\n",
       "   Cleaned_Name  Topics                                         Category  \\\n",
       "0  pramod kumar    -1.0                                       ['Others']   \n",
       "1  abhinav deep     9.0  ['Food Quality', 'Atmosphere', 'Service Issue']   \n",
       "2   vijay nammi    -1.0                                       ['Others']   \n",
       "3    surya ajay    34.0                ['Service Issue', 'Food Quality']   \n",
       "4   sai hithesh     5.0                                 ['Food Options']   \n",
       "\n",
       "   Is_Repeated  Sentiment_Score Customer_Satisfaction  Review_Days  \\\n",
       "0        False        -0.350000           No Response        180.0   \n",
       "1        False         0.000000     High Satisfaction        365.0   \n",
       "2        False        -0.388889           No Response         30.0   \n",
       "3        False        -0.772727     High Satisfaction        365.0   \n",
       "4        False         0.214286           No Response        180.0   \n",
       "\n",
       "   Response_Days  ...  Food Options  Food Quality  Atmosphere  \\\n",
       "0             -1  ...             0             0           0   \n",
       "1            365  ...             0             1           1   \n",
       "2             -1  ...             0             0           0   \n",
       "3            365  ...             0             1           0   \n",
       "4             -1  ...             1             0           0   \n",
       "\n",
       "   Value for Money  Hygiene  Others  Severity_Label  Urgency_Label  \\\n",
       "0                0        0       1               0              1   \n",
       "1                0        0       0               2              0   \n",
       "2                0        0       1               0              1   \n",
       "3                0        0       0               0              1   \n",
       "4                0        0       0               1              0   \n",
       "\n",
       "   Frequency_Label  Unique_Customer_Label  \n",
       "0                1                      1  \n",
       "1                1                      0  \n",
       "2                1                      0  \n",
       "3                1                      0  \n",
       "4                1                      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Final_AB_Complaint_Classification.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4205, 21)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "PyTorch version: 2.5.0+cu121\n",
      "Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Cleaned_Review', 'Cleaned_Name', 'Topics', 'Category',\n",
       "       'Is_Repeated', 'Sentiment_Score', 'Customer_Satisfaction',\n",
       "       'Review_Days', 'Response_Days', 'Service Issue', 'Food Options',\n",
       "       'Food Quality', 'Atmosphere', 'Value for Money', 'Hygiene', 'Others',\n",
       "       'Severity_Label', 'Urgency_Label', 'Frequency_Label',\n",
       "       'Unique_Customer_Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df['Cleaned_Review']\n",
    "y = df[['Service Issue', \"Food Options\", \"Food Quality\", \"Atmosphere\", \"Value for Money\", \"Hygiene\", \"Others\"]]\n",
    "y = y.values  # Convert DataFrame to numpy array\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input text\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch dataset class\n",
    "class ComplaintDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)  # Use float for multi-label\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ComplaintDataset(train_encodings, y_train)\n",
    "test_dataset = ComplaintDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights to handle class imbalance\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train.flatten())\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom loss function\n",
    "class WeightedBCEWithLogitsLoss(torch.nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super().__init__()\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        return self.loss_fn(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments with adjustments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,  # Increase the number of epochs\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"epoch\",  # Change this line from evaluation_strategy to eval_strategy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    # Thresholding predictions for multi-label accuracy\n",
    "    predictions = (p.predictions > 0).astype(int)  # Binary predictions\n",
    "    accuracy = (predictions == p.label_ids).mean(axis=1).mean()  # Mean accuracy across samples\n",
    "    return {\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics  # Use the defined function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9942665a2934253b4c1329465d53c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7146, 'grad_norm': 2.9257380962371826, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.02}\n",
      "{'loss': 0.6922, 'grad_norm': 2.5693769454956055, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.05}\n",
      "{'loss': 0.6836, 'grad_norm': 2.2068824768066406, 'learning_rate': 3e-06, 'epoch': 0.07}\n",
      "{'loss': 0.6621, 'grad_norm': 2.092958927154541, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 0.6515, 'grad_norm': 1.8742966651916504, 'learning_rate': 5e-06, 'epoch': 0.12}\n",
      "{'loss': 0.6262, 'grad_norm': 1.9232337474822998, 'learning_rate': 6e-06, 'epoch': 0.14}\n",
      "{'loss': 0.5995, 'grad_norm': 2.1151862144470215, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.17}\n",
      "{'loss': 0.5596, 'grad_norm': 2.0005648136138916, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.19}\n",
      "{'loss': 0.5186, 'grad_norm': 1.6371268033981323, 'learning_rate': 9e-06, 'epoch': 0.21}\n",
      "{'loss': 0.5038, 'grad_norm': 1.0715683698654175, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 0.5185, 'grad_norm': 1.1927218437194824, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.26}\n",
      "{'loss': 0.475, 'grad_norm': 0.7497061491012573, 'learning_rate': 1.2e-05, 'epoch': 0.29}\n",
      "{'loss': 0.4864, 'grad_norm': 1.7055083513259888, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.31}\n",
      "{'loss': 0.4418, 'grad_norm': 1.054040551185608, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.33}\n",
      "{'loss': 0.4796, 'grad_norm': 1.6517285108566284, 'learning_rate': 1.5e-05, 'epoch': 0.36}\n",
      "{'loss': 0.4219, 'grad_norm': 1.6119987964630127, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4533, 'grad_norm': 1.0444533824920654, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4582, 'grad_norm': 1.205971121788025, 'learning_rate': 1.8e-05, 'epoch': 0.43}\n",
      "{'loss': 0.4284, 'grad_norm': 1.4005045890808105, 'learning_rate': 1.9e-05, 'epoch': 0.45}\n",
      "{'loss': 0.4325, 'grad_norm': 1.958518385887146, 'learning_rate': 2e-05, 'epoch': 0.48}\n",
      "{'loss': 0.423, 'grad_norm': 1.2932897806167603, 'learning_rate': 2.1e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4449, 'grad_norm': 2.022123098373413, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.52}\n",
      "{'loss': 0.4096, 'grad_norm': 1.3932307958602905, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.55}\n",
      "{'loss': 0.4338, 'grad_norm': 1.3240934610366821, 'learning_rate': 2.4e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3928, 'grad_norm': 1.352746605873108, 'learning_rate': 2.5e-05, 'epoch': 0.59}\n",
      "{'loss': 0.4315, 'grad_norm': 1.8512351512908936, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.62}\n",
      "{'loss': 0.4306, 'grad_norm': 2.1263437271118164, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.64}\n",
      "{'loss': 0.4336, 'grad_norm': 1.9931260347366333, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3944, 'grad_norm': 1.50955069065094, 'learning_rate': 2.9e-05, 'epoch': 0.69}\n",
      "{'loss': 0.4129, 'grad_norm': 3.4031190872192383, 'learning_rate': 3e-05, 'epoch': 0.71}\n",
      "{'loss': 0.418, 'grad_norm': 1.6353425979614258, 'learning_rate': 3.1e-05, 'epoch': 0.74}\n",
      "{'loss': 0.3918, 'grad_norm': 2.4496359825134277, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.76}\n",
      "{'loss': 0.4199, 'grad_norm': 1.364378809928894, 'learning_rate': 3.3e-05, 'epoch': 0.78}\n",
      "{'loss': 0.4122, 'grad_norm': 3.563061475753784, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.81}\n",
      "{'loss': 0.4139, 'grad_norm': 2.17985200881958, 'learning_rate': 3.5e-05, 'epoch': 0.83}\n",
      "{'loss': 0.4079, 'grad_norm': 1.41143000125885, 'learning_rate': 3.6e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3842, 'grad_norm': 1.8821336030960083, 'learning_rate': 3.7e-05, 'epoch': 0.88}\n",
      "{'loss': 0.3807, 'grad_norm': 1.989211916923523, 'learning_rate': 3.8e-05, 'epoch': 0.9}\n",
      "{'loss': 0.3905, 'grad_norm': 1.7016957998275757, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.93}\n",
      "{'loss': 0.4007, 'grad_norm': 1.6524837017059326, 'learning_rate': 4e-05, 'epoch': 0.95}\n",
      "{'loss': 0.3665, 'grad_norm': 1.3040838241577148, 'learning_rate': 4.1e-05, 'epoch': 0.97}\n",
      "{'loss': 0.4111, 'grad_norm': 11.300339698791504, 'learning_rate': 4.2e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1f18b107944e0ab50dad13fb506af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36681947112083435, 'eval_accuracy': 0.8235094275522337, 'eval_runtime': 175.2018, 'eval_samples_per_second': 4.8, 'eval_steps_per_second': 0.605, 'epoch': 1.0}\n",
      "{'loss': 0.3436, 'grad_norm': 7.286369323730469, 'learning_rate': 4.3e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3715, 'grad_norm': 1.7943238019943237, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.05}\n",
      "{'loss': 0.3326, 'grad_norm': 1.9986101388931274, 'learning_rate': 4.5e-05, 'epoch': 1.07}\n",
      "{'loss': 0.3612, 'grad_norm': 1.4151784181594849, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.09}\n",
      "{'loss': 0.3661, 'grad_norm': 2.319204568862915, 'learning_rate': 4.7e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3697, 'grad_norm': 1.7289930582046509, 'learning_rate': 4.8e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3839, 'grad_norm': 1.7256921529769897, 'learning_rate': 4.9e-05, 'epoch': 1.16}\n",
      "{'loss': 0.3693, 'grad_norm': 2.247877836227417, 'learning_rate': 5e-05, 'epoch': 1.19}\n",
      "{'loss': 0.346, 'grad_norm': 1.6607941389083862, 'learning_rate': 4.934469200524246e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3649, 'grad_norm': 1.953329086303711, 'learning_rate': 4.868938401048493e-05, 'epoch': 1.24}\n",
      "{'loss': 0.3877, 'grad_norm': 1.6536595821380615, 'learning_rate': 4.803407601572739e-05, 'epoch': 1.26}\n",
      "{'loss': 0.3329, 'grad_norm': 1.591418981552124, 'learning_rate': 4.737876802096986e-05, 'epoch': 1.28}\n",
      "{'loss': 0.3115, 'grad_norm': 2.200941324234009, 'learning_rate': 4.672346002621232e-05, 'epoch': 1.31}\n",
      "{'loss': 0.3377, 'grad_norm': 3.5349552631378174, 'learning_rate': 4.606815203145479e-05, 'epoch': 1.33}\n",
      "{'loss': 0.3539, 'grad_norm': 2.2283685207366943, 'learning_rate': 4.541284403669725e-05, 'epoch': 1.35}\n",
      "{'loss': 0.3427, 'grad_norm': 3.265967845916748, 'learning_rate': 4.475753604193971e-05, 'epoch': 1.38}\n",
      "{'loss': 0.3247, 'grad_norm': 1.4356080293655396, 'learning_rate': 4.410222804718218e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3625, 'grad_norm': 1.6823334693908691, 'learning_rate': 4.344692005242464e-05, 'epoch': 1.43}\n",
      "{'loss': 0.2926, 'grad_norm': 2.1519296169281006, 'learning_rate': 4.2791612057667106e-05, 'epoch': 1.45}\n",
      "{'loss': 0.3368, 'grad_norm': 1.879112720489502, 'learning_rate': 4.2136304062909573e-05, 'epoch': 1.47}\n",
      "{'loss': 0.355, 'grad_norm': 3.8269765377044678, 'learning_rate': 4.1480996068152034e-05, 'epoch': 1.5}\n",
      "{'loss': 0.3475, 'grad_norm': 2.371346950531006, 'learning_rate': 4.0825688073394495e-05, 'epoch': 1.52}\n",
      "{'loss': 0.3124, 'grad_norm': 3.0664825439453125, 'learning_rate': 4.017038007863696e-05, 'epoch': 1.54}\n",
      "{'loss': 0.3678, 'grad_norm': 2.879847764968872, 'learning_rate': 3.9515072083879424e-05, 'epoch': 1.57}\n",
      "{'loss': 0.2887, 'grad_norm': 2.103696823120117, 'learning_rate': 3.885976408912189e-05, 'epoch': 1.59}\n",
      "{'loss': 0.3309, 'grad_norm': 1.1074683666229248, 'learning_rate': 3.820445609436435e-05, 'epoch': 1.62}\n",
      "{'loss': 0.3314, 'grad_norm': 2.346397876739502, 'learning_rate': 3.754914809960682e-05, 'epoch': 1.64}\n",
      "{'loss': 0.3712, 'grad_norm': 4.193603038787842, 'learning_rate': 3.689384010484928e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3224, 'grad_norm': 2.205274820327759, 'learning_rate': 3.623853211009174e-05, 'epoch': 1.69}\n",
      "{'loss': 0.2865, 'grad_norm': 1.0779619216918945, 'learning_rate': 3.558322411533421e-05, 'epoch': 1.71}\n",
      "{'loss': 0.3162, 'grad_norm': 4.234908103942871, 'learning_rate': 3.492791612057667e-05, 'epoch': 1.73}\n",
      "{'loss': 0.3855, 'grad_norm': 2.061117649078369, 'learning_rate': 3.427260812581914e-05, 'epoch': 1.76}\n",
      "{'loss': 0.3078, 'grad_norm': 1.881655216217041, 'learning_rate': 3.3617300131061605e-05, 'epoch': 1.78}\n",
      "{'loss': 0.3176, 'grad_norm': 3.1907262802124023, 'learning_rate': 3.2961992136304066e-05, 'epoch': 1.81}\n",
      "{'loss': 0.3491, 'grad_norm': 1.5904332399368286, 'learning_rate': 3.230668414154653e-05, 'epoch': 1.83}\n",
      "{'loss': 0.2903, 'grad_norm': 1.5852415561676025, 'learning_rate': 3.1651376146788995e-05, 'epoch': 1.85}\n",
      "{'loss': 0.3304, 'grad_norm': 2.111995220184326, 'learning_rate': 3.0996068152031456e-05, 'epoch': 1.88}\n",
      "{'loss': 0.3409, 'grad_norm': 2.068782329559326, 'learning_rate': 3.0340760157273916e-05, 'epoch': 1.9}\n",
      "{'loss': 0.3034, 'grad_norm': 1.9801146984100342, 'learning_rate': 2.9685452162516387e-05, 'epoch': 1.92}\n",
      "{'loss': 0.3026, 'grad_norm': 2.1732943058013916, 'learning_rate': 2.9030144167758848e-05, 'epoch': 1.95}\n",
      "{'loss': 0.2692, 'grad_norm': 2.07539701461792, 'learning_rate': 2.8374836173001313e-05, 'epoch': 1.97}\n",
      "{'loss': 0.2692, 'grad_norm': 2.174729347229004, 'learning_rate': 2.7719528178243777e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7555206d1b2a485d911520f539a3e445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32727956771850586, 'eval_accuracy': 0.8462714455580091, 'eval_runtime': 179.1888, 'eval_samples_per_second': 4.693, 'eval_steps_per_second': 0.592, 'epoch': 2.0}\n",
      "{'loss': 0.2957, 'grad_norm': 3.009728193283081, 'learning_rate': 2.7064220183486238e-05, 'epoch': 2.02}\n",
      "{'loss': 0.2766, 'grad_norm': 2.741769313812256, 'learning_rate': 2.6408912188728702e-05, 'epoch': 2.04}\n",
      "{'loss': 0.2591, 'grad_norm': 1.2283294200897217, 'learning_rate': 2.575360419397117e-05, 'epoch': 2.07}\n",
      "{'loss': 0.2396, 'grad_norm': 2.654691219329834, 'learning_rate': 2.5098296199213634e-05, 'epoch': 2.09}\n",
      "{'loss': 0.2696, 'grad_norm': 4.424205780029297, 'learning_rate': 2.4442988204456098e-05, 'epoch': 2.11}\n",
      "{'loss': 0.2466, 'grad_norm': 4.38755464553833, 'learning_rate': 2.378768020969856e-05, 'epoch': 2.14}\n",
      "{'loss': 0.2571, 'grad_norm': 2.9645440578460693, 'learning_rate': 2.3132372214941023e-05, 'epoch': 2.16}\n",
      "{'loss': 0.2582, 'grad_norm': 1.682331919670105, 'learning_rate': 2.2477064220183487e-05, 'epoch': 2.19}\n",
      "{'loss': 0.2037, 'grad_norm': 1.8755838871002197, 'learning_rate': 2.182175622542595e-05, 'epoch': 2.21}\n",
      "{'loss': 0.2484, 'grad_norm': 3.1355361938476562, 'learning_rate': 2.1166448230668416e-05, 'epoch': 2.23}\n",
      "{'loss': 0.2392, 'grad_norm': 2.394934892654419, 'learning_rate': 2.0511140235910877e-05, 'epoch': 2.26}\n",
      "{'loss': 0.2664, 'grad_norm': 3.0408167839050293, 'learning_rate': 1.9855832241153344e-05, 'epoch': 2.28}\n",
      "{'loss': 0.2195, 'grad_norm': 1.7217050790786743, 'learning_rate': 1.9200524246395805e-05, 'epoch': 2.3}\n",
      "{'loss': 0.2212, 'grad_norm': 3.3250482082366943, 'learning_rate': 1.854521625163827e-05, 'epoch': 2.33}\n",
      "{'loss': 0.2376, 'grad_norm': 1.6207020282745361, 'learning_rate': 1.7889908256880737e-05, 'epoch': 2.35}\n",
      "{'loss': 0.2321, 'grad_norm': 3.8200674057006836, 'learning_rate': 1.7234600262123198e-05, 'epoch': 2.38}\n",
      "{'loss': 0.2132, 'grad_norm': 1.3459932804107666, 'learning_rate': 1.6579292267365662e-05, 'epoch': 2.4}\n",
      "{'loss': 0.2322, 'grad_norm': 3.045346736907959, 'learning_rate': 1.5923984272608126e-05, 'epoch': 2.42}\n",
      "{'loss': 0.2124, 'grad_norm': 3.1526758670806885, 'learning_rate': 1.526867627785059e-05, 'epoch': 2.45}\n",
      "{'loss': 0.1896, 'grad_norm': 1.2818827629089355, 'learning_rate': 1.4613368283093053e-05, 'epoch': 2.47}\n",
      "{'loss': 0.2669, 'grad_norm': 2.026839256286621, 'learning_rate': 1.3958060288335518e-05, 'epoch': 2.49}\n",
      "{'loss': 0.2002, 'grad_norm': 3.6809258460998535, 'learning_rate': 1.3302752293577984e-05, 'epoch': 2.52}\n",
      "{'loss': 0.2159, 'grad_norm': 2.4506330490112305, 'learning_rate': 1.2647444298820446e-05, 'epoch': 2.54}\n",
      "{'loss': 0.2057, 'grad_norm': 1.8701967000961304, 'learning_rate': 1.199213630406291e-05, 'epoch': 2.57}\n",
      "{'loss': 0.2564, 'grad_norm': 4.690910816192627, 'learning_rate': 1.1336828309305373e-05, 'epoch': 2.59}\n",
      "{'loss': 0.2197, 'grad_norm': 3.3293981552124023, 'learning_rate': 1.0681520314547839e-05, 'epoch': 2.61}\n",
      "{'loss': 0.2307, 'grad_norm': 2.311671495437622, 'learning_rate': 1.0026212319790301e-05, 'epoch': 2.64}\n",
      "{'loss': 0.2157, 'grad_norm': 2.335528612136841, 'learning_rate': 9.370904325032766e-06, 'epoch': 2.66}\n",
      "{'loss': 0.2462, 'grad_norm': 5.312251567840576, 'learning_rate': 8.71559633027523e-06, 'epoch': 2.68}\n",
      "{'loss': 0.2569, 'grad_norm': 2.4679431915283203, 'learning_rate': 8.060288335517694e-06, 'epoch': 2.71}\n",
      "{'loss': 0.2391, 'grad_norm': 3.617896795272827, 'learning_rate': 7.4049803407601575e-06, 'epoch': 2.73}\n",
      "{'loss': 0.2376, 'grad_norm': 1.4692538976669312, 'learning_rate': 6.749672346002621e-06, 'epoch': 2.76}\n",
      "{'loss': 0.2236, 'grad_norm': 6.333867073059082, 'learning_rate': 6.094364351245085e-06, 'epoch': 2.78}\n",
      "{'loss': 0.2555, 'grad_norm': 3.3842580318450928, 'learning_rate': 5.4390563564875494e-06, 'epoch': 2.8}\n",
      "{'loss': 0.2234, 'grad_norm': 1.7407374382019043, 'learning_rate': 4.783748361730013e-06, 'epoch': 2.83}\n",
      "{'loss': 0.2135, 'grad_norm': 3.2868361473083496, 'learning_rate': 4.128440366972477e-06, 'epoch': 2.85}\n",
      "{'loss': 0.2866, 'grad_norm': 4.202661991119385, 'learning_rate': 3.4731323722149413e-06, 'epoch': 2.87}\n",
      "{'loss': 0.2188, 'grad_norm': 4.098069190979004, 'learning_rate': 2.817824377457405e-06, 'epoch': 2.9}\n",
      "{'loss': 0.2293, 'grad_norm': 2.9904866218566895, 'learning_rate': 2.1625163826998694e-06, 'epoch': 2.92}\n",
      "{'loss': 0.2136, 'grad_norm': 2.100583076477051, 'learning_rate': 1.507208387942333e-06, 'epoch': 2.95}\n",
      "{'loss': 0.22, 'grad_norm': 2.1491243839263916, 'learning_rate': 8.51900393184797e-07, 'epoch': 2.97}\n",
      "{'loss': 0.2071, 'grad_norm': 1.8227903842926025, 'learning_rate': 1.9659239842726081e-07, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3d471a53c143248a1a17949ed38124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3148002624511719, 'eval_accuracy': 0.859860710039069, 'eval_runtime': 178.0788, 'eval_samples_per_second': 4.723, 'eval_steps_per_second': 0.595, 'epoch': 3.0}\n",
      "{'train_runtime': 8005.2001, 'train_samples_per_second': 1.261, 'train_steps_per_second': 0.158, 'train_loss': 0.3473458559571611, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1263, training_loss=0.3473458559571611, metrics={'train_runtime': 8005.2001, 'train_samples_per_second': 1.261, 'train_steps_per_second': 0.158, 'total_flos': 409725472825800.0, 'train_loss': 0.3473458559571611, 'epoch': 3.0})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db369fb8b64b474aa95e631ddeac930a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get classification report\n",
    "# print(classification_report(y_test, preds, target_names=[\n",
    "#     'Service Issue', 'Technical Issue', 'Food Quality', \n",
    "#     'Atmosphere', 'Value for Money', 'Others', 'Hygiene'\n",
    "# ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  Service Issue       0.67      0.55      0.61       173\n",
      "   Food Options       0.77      0.71      0.74       188\n",
      "   Food Quality       0.77      0.45      0.56       191\n",
      "     Atmosphere       0.75      0.70      0.72       191\n",
      "Value for Money       0.56      0.23      0.33        39\n",
      "         Others       0.88      0.43      0.58        70\n",
      "        Hygiene       0.59      0.42      0.49       346\n",
      "\n",
      "      micro avg       0.70      0.53      0.60      1198\n",
      "      macro avg       0.71      0.50      0.57      1198\n",
      "   weighted avg       0.70      0.53      0.59      1198\n",
      "    samples avg       0.54      0.51      0.52      1198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Gradious_Final_Project\\abr\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to binary format\n",
    "preds = (predictions.predictions > 0.5).astype(int)\n",
    "\n",
    "# Get classification report\n",
    "print(classification_report(y_test, preds, target_names=[\n",
    "    'Service Issue', 'Food Options', 'Food Quality', \n",
    "    'Atmosphere', 'Value for Money', 'Others', 'Hygiene'\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-3.7128906 , -1.8447266 , -0.09204102, ..., -4.4179688 ,\n",
       "        -4.6484375 ,  0.5004883 ],\n",
       "       [-4.5390625 ,  1.4921875 ,  0.6582031 , ..., -2.6933594 ,\n",
       "        -4.1796875 , -1.9072266 ],\n",
       "       [-0.640625  , -4.9140625 , -2.3671875 , ..., -5.3398438 ,\n",
       "        -4.1640625 ,  0.9921875 ],\n",
       "       ...,\n",
       "       [-1.5078125 , -3.7675781 , -4.4296875 , ..., -5.390625  ,\n",
       "        -4.078125  ,  0.30566406],\n",
       "       [-3.3378906 , -3.0566406 , -4.09375   , ..., -4.3945312 ,\n",
       "        -4.1679688 , -0.36083984],\n",
       "       [ 0.66748047, -4.9570312 , -3.2832031 , ..., -5.4140625 ,\n",
       "        -3.2324219 , -0.16320801]], dtype=float32), label_ids=array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32), metrics={'test_loss': 0.3148002624511719, 'test_accuracy': 0.859860710039069, 'test_runtime': 145.7177, 'test_samples_per_second': 5.771, 'test_steps_per_second': 0.727})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dceaa7f113e94d41af606b006c13bd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved as 'model_evaluation_output.pkl'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Gradious_Final_Project\\abr\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to binary format\n",
    "preds = (predictions.predictions > 0.5).astype(int)\n",
    "\n",
    "# Get the classification report\n",
    "report = classification_report(y_test, preds, target_names=[\n",
    "    'Service Issue', \"Food Options\", 'Food Quality',\n",
    "    'Atmosphere', 'Value for Money', 'Others', 'Hygiene'\n",
    "], output_dict=True)  # Use output_dict=True to get the report as a dictionary\n",
    "\n",
    "# Save the predictions and classification report to a dictionary\n",
    "output_data = {\n",
    "    'predictions': preds,\n",
    "    'classification_report': report\n",
    "}\n",
    "\n",
    "# Save the dictionary as a .pkl file\n",
    "with open('model_evaluation_output.pkl', 'wb') as file:\n",
    "    pickle.dump(output_data, file)\n",
    "\n",
    "print(\"Output saved as 'model_evaluation_output.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./results.\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "save_directory = './results'  # Path where your fine-tuned model is saved\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_directory}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load the fine-tuned BERT model and tokenizer\n",
    "model_path = './results' # Path where the saved model and tokenizer are stored\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify a new review\n",
    "def classify_review(review):\n",
    "    # Tokenize the review\n",
    "    inputs = tokenizer(review, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "    # Move tensors to GPU if available\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    # Get the model's prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Apply sigmoid to get probabilities for multi-label classification\n",
    "    logits = outputs.logits\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    # Convert probabilities to binary predictions (threshold of 0.5)\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "\n",
    "    # Define the categories\n",
    "    categories = ['Service Issue', \"Food Options\", 'Food Quality', \n",
    "                  'Atmosphere', 'Value for Money', 'Others', 'Hygiene']\n",
    "\n",
    "    # Extract the categories where predictions are True\n",
    "    predicted_categories = [category for category, pred in zip(categories, predictions[0]) if pred]\n",
    "\n",
    "    return predicted_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "new_review = \"Service and food not good; I don't like the ambience.\"\n",
    "classification_result = classify_review(new_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Categories:\n",
      "['Service Issue', 'Food Quality', 'Atmosphere']\n"
     ]
    }
   ],
   "source": [
    "# Print only the categories that are relevant\n",
    "print(\"Relevant Categories:\")\n",
    "print(classification_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification function has been saved to classification_function.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the function to a pickle file\n",
    "with open('classification_function.pkl', 'wb') as f:\n",
    "    pickle.dump(classify_review, f)\n",
    "\n",
    "print(\"Classification function has been saved to classification_function.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Categories from loaded function:\n",
      "['Hygiene']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the classification function from the pickle file\n",
    "with open('classification_function.pkl', 'rb') as f:\n",
    "    classify_review = pickle.load(f)\n",
    "\n",
    "# Example review\n",
    "new_review = \"I had a great time, but the food was subpar.\"\n",
    "classification_result = classify_review(new_review)\n",
    "\n",
    "print(\"Relevant Categories from loaded function:\")\n",
    "print(classification_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to get complaint counts, categories, and total complaints for the specified days\n",
    "def get_complaint_counts(df, days):\n",
    "    # Filter the DataFrame to get rows where Review_Days is less than or equal to the specified days\n",
    "    filtered_df = df[df['Review_Days'] <= days]\n",
    "\n",
    "    # Define the category columns explicitly\n",
    "    category_columns = [\n",
    "        'Service Issue',\n",
    "        'Food Options',\n",
    "        'Food Quality',\n",
    "        'Atmosphere',\n",
    "        'Value for Money',\n",
    "        'Others',\n",
    "        'Hygiene'\n",
    "    ]\n",
    "\n",
    "    # Count occurrences for each specified category\n",
    "    category_counts = filtered_df[category_columns].sum()  # Use the list of column names\n",
    "\n",
    "    # Create a dictionary to hold the categories and their counts\n",
    "    complaint_info = {\n",
    "        'categories': category_counts.index.tolist(),\n",
    "        'counts': category_counts.values.tolist(),\n",
    "        'total_complaints': filtered_df.shape[0]  # Count of total complaints\n",
    "    }\n",
    "    \n",
    "    return complaint_info\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 30  # Change this to 30, 60, or 90 as needed\n",
    "complaint_info = get_complaint_counts(df, days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complaint Counts for the Last 30 Days:\n",
      "Service Issue: 15\n",
      "Food Options: 11\n",
      "Food Quality: 17\n",
      "Atmosphere: 14\n",
      "Value for Money: 1\n",
      "Others: 22\n",
      "Hygiene: 5\n",
      "Total Complaints for the Last 30 Days: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nComplaint Counts for the Last {days} Days:\")\n",
    "for category, count in zip(complaint_info['categories'], complaint_info['counts']):\n",
    "        print(f\"{category}: {count}\")\n",
    "print(f\"Total Complaints for the Last {days} Days: {complaint_info['total_complaints']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complaint Counts for the Last 30 Days:\n",
      "Service Issue: 15\n",
      "Food Options: 11\n",
      "Food Quality: 17\n",
      "Atmosphere: 14\n",
      "Value for Money: 1\n",
      "Others: 22\n",
      "Hygiene: 5\n",
      "Total Complaints for the Last 30 Days: 64\n",
      "Complaint counting function has been saved to complaint_functions.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Function to get complaint counts, categories, and total complaints for the specified days\n",
    "def get_complaint_counts(df, days):\n",
    "    # Filter the DataFrame to get rows where Review_Days is less than or equal to the specified days\n",
    "    filtered_df = df[df['Review_Days'] <= days]\n",
    "\n",
    "    # Define the category columns explicitly\n",
    "    category_columns = [\n",
    "        'Service Issue',\n",
    "        'Food Options',\n",
    "        'Food Quality',\n",
    "        'Atmosphere',\n",
    "        'Value for Money',\n",
    "        'Others',\n",
    "        'Hygiene'\n",
    "    ]\n",
    "\n",
    "    # Count occurrences for each specified category\n",
    "    category_counts = filtered_df[category_columns].sum()  # Use the list of column names\n",
    "\n",
    "    # Create a dictionary to hold the categories and their counts\n",
    "    complaint_info = {\n",
    "        'categories': category_counts.index.tolist(),\n",
    "        'counts': category_counts.values.tolist(),\n",
    "        'total_complaints': filtered_df.shape[0]  # Count of total complaints\n",
    "    }\n",
    "    \n",
    "    return complaint_info\n",
    "\n",
    "# Specify the days you want to check\n",
    "days = 30  # Change this to 30, 60, or 90 as needed\n",
    "complaint_info = get_complaint_counts(df, days)\n",
    "\n",
    "# Print the complaint counts\n",
    "print(f\"\\nComplaint Counts for the Last {days} Days:\")\n",
    "for category, count in zip(complaint_info['categories'], complaint_info['counts']):\n",
    "    print(f\"{category}: {count}\")\n",
    "print(f\"Total Complaints for the Last {days} Days: {complaint_info['total_complaints']}\")\n",
    "\n",
    "# Save the function to a pickle file\n",
    "functions = {\n",
    "    'get_complaint_counts': get_complaint_counts\n",
    "}\n",
    "\n",
    "with open('complaint_functions.pkl', 'wb') as f:\n",
    "    pickle.dump(functions, f)\n",
    "\n",
    "print(\"Complaint counting function has been saved to complaint_functions.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39036e1325ce49a3b2d00bca911f1a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Gradious_Final_Project\\abr\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sai\\.cache\\huggingface\\hub\\models--distilgpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00573193653403e9c8401c762e1cb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93827180a8ec42b7834c2fffd6f53715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5de2d1b6144055baa0a265636df363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5f893212674949896a1edb54d77f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486ff0b2aaee4723888584880db9c9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779f92efa6254a638828cb7210f77d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilGPT-2 model and tokenizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# # Load the DistilGPT-2 model and tokenizer\n",
    "# model_name = 'distilgpt2'\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# # Save the model and tokenizer in a single pickle file\n",
    "# with open('distil_gpt_model.pkl', 'wb') as f:\n",
    "#     pickle.dump({'model': model, 'tokenizer': tokenizer}, f)\n",
    "\n",
    "# print(\"DistilGPT-2 model and tokenizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Response:\n",
      "If you have a problem with your service, you can contact Customer Service at 1-800-222-8477.\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# import torch\n",
    "\n",
    "# # Load DistilGPT-2 model and tokenizer from a single pickle file\n",
    "# with open('distil_gpt_model.pkl', 'rb') as f:\n",
    "#     gpt_data = pickle.load(f)\n",
    "#     model = gpt_data['model']\n",
    "#     tokenizer = gpt_data['tokenizer']\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# def generate_response(categories, severity, urgency, complaint_type):\n",
    "#     prompt = (\n",
    "#         f\"You are a customer service representative responding to a complaint.\\n\"\n",
    "#         f\"Categories: {', '.join(categories)}\\n\"\n",
    "#         f\"Severity: {severity}\\n\"\n",
    "#         f\"Urgency: {urgency}\\n\"\n",
    "#         f\"Complaint Type: {complaint_type}\\n\"\n",
    "#         \"Imagine the customer feels frustrated due to this issue. \"\n",
    "#         \"Respond in a way that shows understanding and offers a resolution.\"\n",
    "#     )\n",
    "    \n",
    "#     # Encode the prompt\n",
    "#     inputs = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "#     # Set pad_token_id and attention_mask\n",
    "#     pad_token_id = tokenizer.eos_token_id\n",
    "#     attention_mask = torch.ones(inputs.shape, device=device)\n",
    "\n",
    "#     # Generate response\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model.generate(\n",
    "#             inputs,\n",
    "#             max_length=150,\n",
    "#             num_return_sequences=1,\n",
    "#             no_repeat_ngram_size=2,\n",
    "#             early_stopping=True,\n",
    "#             num_beams=5,\n",
    "#             pad_token_id=pad_token_id,\n",
    "#             attention_mask=attention_mask,\n",
    "#             do_sample=True,\n",
    "#             temperature=0.7,\n",
    "#             top_k=50,\n",
    "#             top_p=0.95\n",
    "#         )\n",
    "\n",
    "#     # Decode and return the generated response\n",
    "#     response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "#     return response.replace(prompt, \"\").strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# categories = [\"Service Issue\", \"Food Quality\"]\n",
    "# severity = \"High\"\n",
    "# urgency = \"Urgent\"\n",
    "# complaint_type = \"First Time\"\n",
    "\n",
    "# auto_response = generate_response(categories, severity, urgency, complaint_type)\n",
    "# print(\"Auto-Response:\")\n",
    "# print(auto_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Response:\n",
      "Hi,\n",
      "We regret the inconveniences you have faced. We understand that service issues can be frustrating, and we are committed to resolving this. We take food quality seriously, and we apologize for not meeting your expectations.We recognize the urgency of this matter.\n",
      "We will prioritize your concern and address it immediately.We recognize that this type of complaint has been registered before, and we are committed to resolving it to prevent future occurrences.\n",
      "\n",
      "We request you to share your contact information at wecare@restaurant.com. We shall connect with you in no time and assist you with the issue raised. We assure you that this won't happen again next time.\n",
      "\n",
      "Team Restaurant\n"
     ]
    }
   ],
   "source": [
    "def generate_response(categories, severity, urgency, complaint_type, previous_complaint):\n",
    "    # Initialize the base response\n",
    "    base_response = (\n",
    "        \"Hi,\\n\"\n",
    "        \"We regret the inconveniences you have faced.\"\n",
    "    )\n",
    "\n",
    "    # Dynamic sentence parts based on categories\n",
    "    category_sentences = {\n",
    "        'Service Issue': \"We understand that service issues can be frustrating, and we are committed to resolving this.\",\n",
    "        'Food Options': \"We appreciate your feedback on our food options, and we are continually working to enhance our menu.\",\n",
    "        'Food Quality': \"We take food quality seriously, and we apologize for not meeting your expectations.\",\n",
    "        'Atmosphere': \"Creating a pleasant atmosphere is important to us, and we are sorry that we fell short.\",\n",
    "        'Value for Money': \"We strive to provide value for money, and we appreciate your input on this matter.\",\n",
    "        'Hygiene': \"Hygiene is our top priority, and we are dedicated to maintaining the highest standards.\",\n",
    "        'Others': \"Thank you for sharing your thoughts; we take all feedback seriously.\"\n",
    "    }\n",
    "\n",
    "    # Construct the response based on categories\n",
    "    category_responses = [category_sentences[category] for category in categories if category in category_sentences]\n",
    "    \n",
    "    # Add severity and urgency\n",
    "    if severity == \"High\":\n",
    "        severity_response = \"We recognize the urgency of this matter.\"\n",
    "    elif severity == \"Medium\":\n",
    "        severity_response = \"We acknowledge the issues you've raised.\"\n",
    "    else:\n",
    "        severity_response = \"We appreciate your feedback.\"\n",
    "\n",
    "    if urgency == \"Urgent\":\n",
    "        urgency_response = \"We will prioritize your concern and address it immediately.\"\n",
    "    else:\n",
    "        urgency_response = \"We will take your feedback into consideration and work on improvements.\"\n",
    "\n",
    "    # Append the responses to the base response\n",
    "    full_response = f\"{base_response}\"+\" \" + \" \".join(category_responses) + f\"{severity_response}\\n{urgency_response}\"\n",
    "    \n",
    "    # Add repeated or first-time complaint information based on the type of complaint\n",
    "    if previous_complaint:\n",
    "        full_response += \"We recognize that this type of complaint has been registered before, and we are committed to resolving it to prevent future occurrences.\"\n",
    "    else:\n",
    "        full_response += \"This is the first time we have received this type of complaint, and we assure you it will be addressed promptly.\"\n",
    "\n",
    "    # Closing statement without the restaurant name\n",
    "    full_response += \"\\n\\nWe request you to share your contact information at wecare@restaurant.com. We shall connect with you in no time and assist you with the issue raised. We assure you that this won't happen again next time.\\n\\nTeam Restaurant\"\n",
    "\n",
    "    return full_response\n",
    "\n",
    "# Example usage\n",
    "categories = [\"Service Issue\", \"Food Quality\"]\n",
    "severity = \"High\"\n",
    "urgency = \"Urgent\"\n",
    "complaint_type = \"First Time\"\n",
    "previous_complaint = True  # Set to True if this type of complaint has been registered before\n",
    "\n",
    "auto_response = generate_response(categories, severity, urgency, complaint_type, previous_complaint)\n",
    "print(\"Auto-Response:\")\n",
    "print(auto_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file 'response_generator.pkl' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a pickle file\n",
    "with open('response_generator.pkl', 'wb') as file:\n",
    "    pickle.dump(generate_response, file)\n",
    "\n",
    "print(\"Pickle file 'response_generator.pkl' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'get_complaint_counts': <function get_complaint_counts at 0x000001B0255660E0>}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Example of loading a pickle file\n",
    "with open('complaint_functions.pkl', 'rb') as f:\n",
    "    obj = pickle.load(f)\n",
    "print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
